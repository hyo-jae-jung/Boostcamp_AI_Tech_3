{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a4da1c3",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network(CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8631e12",
   "metadata": {},
   "source": [
    "https://cs231n.github.io/convolutional-networks/#conv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e3717b",
   "metadata": {},
   "source": [
    "Convolutional Neural Network를 왜 쓰냐?  \n",
    "overfitting을 줄이기 위해서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3df7a0",
   "metadata": {},
   "source": [
    "채널을 늘리는 이유는?  \n",
    "원본과 비슷한 샘플을 만드는건가?  그런듯?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84014c1",
   "metadata": {},
   "source": [
    "채널을 줄이는 이유 중 하나는 파라미터 개수를 줄이기 위함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3933abfe",
   "metadata": {},
   "source": [
    "채널 수 = 필터 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae6a08",
   "metadata": {},
   "source": [
    "conv에 이미지를 입력하면 n개의 채널로 n개의 샘플이미지를 만든다  \n",
    "pooling으로 각 샘플이미지를 축소하면서 정수만 추출  \n",
    "결과물을 채널을 축소나 평탄화를 사용해서 vector로 만들고  \n",
    "Fully Connected Layer(Dense layer)를 통과시켜서 예측값을 뽑는다.  \n",
    "예측값과 타겟으로 loss를 측정하고 loss를 줄이는 방향으로 업데이트를 하기위해  \n",
    "파라미터들의 편미분값을 구하고 업데이트한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91ae5a",
   "metadata": {},
   "source": [
    "space dimension : 이미지의 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487cf962",
   "metadata": {},
   "source": [
    "### ※※개인적으로 이해가 잘 안됐던 부분※※\n",
    "\n",
    "CNN에서 파라미터의 개수를 구하는 방법은 알고 있지만 계산 방법에 대해서 의문이 들었다. 해당 의문이 풀리자 CNN에 대한 답답함이 사라짐. 계속 가지고 있던 의문이 이거였던 것 같다. 이해하니 채널크기나 파라미터의 개수가 자연스럽게 받아들여짐  \n",
    "\n",
    "CNN에서 다음 레이어로 넘어갈 때 파라미터는 (kernel size) x (input chennal) x (output chennal) 이렇게 구해지는데 세 값 모두 사용자가 조절을 할 수 있는 수이다. 만약 MLP라면 (input dimension) x (output dimension)이 될텐데 imput dimension은 input data에 fully connected하기 때문에 데이터의 차원 수에 묶이고 output dimension은 CNN의 output chennal과 같이 사용자가 정한다. MLP의 input dimension은 CNN의 kernel size와 input chennal에 대응되는데 MLP는 고정인데 CNN은 고정이 아니다. 이 차이가 CNN을 특별하게 만들어 준다.  \n",
    "\n",
    "input dimension > kernel size + input chennal  \n",
    "\n",
    "CNN은 데이터의 차원에 fully connected하게 대응을 하는게 아니라 제한된 파라미터만 가지고 계산을 한다. 왜? overfitting을 줄이기 위해서!  \n",
    "kernel을 filter로 표현하고 CNN 설명에서 matrix or tensor로 설명을 하는건 이미지파일이 가지는 데이터의 모양이 tensor여서 이미지파일에 맞춘 설명이라고 할 수 있다.(왜? 이해를 돕기 위해서??) CNN은 1차원인 데이터에도 적용 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a416de63",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb05fc",
   "metadata": {},
   "source": [
    "# Modern CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9245aa8c",
   "metadata": {},
   "source": [
    "### ILSVRC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07877c58",
   "metadata": {},
   "source": [
    "### AlexNet\n",
    "\n",
    "**Rectifued Linear Unit (ReLU) activation**  \n",
    " - Preserves properties of linear models\n",
    " - Easy to optimize with gradient descent\n",
    " - Good generalization\n",
    " - Overcome the vanishing gradient problem\n",
    " \n",
    "GPU implementation(2 GPUs)  \n",
    "Local response normalization, Overlapping pooling  \n",
    "**Data augmentation**  \n",
    "**Dropout**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8666bad5",
   "metadata": {},
   "source": [
    "### VGGNet\n",
    "\n",
    "**Increasing depth with 3x3 convolution filters (with stride 1)**  \n",
    "1x1 convolution for fully connected layers  \n",
    "Dropout(p=0.5)  \n",
    "VGG16, VGG19  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa6f7f",
   "metadata": {},
   "source": [
    "why 3x3 convolution?\n",
    "- parameter 개수를 줄이기 위해서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e90df24",
   "metadata": {},
   "source": [
    "### GoogLeNet\n",
    "\n",
    "Inception Block : 하나의 input에 대해서 여러개의 필터로 계산했다가 합치는 컨셉  \n",
    "\n",
    "중요한건  \n",
    "**1x1 convolution으로 채널을 줄이면서 파라미터의 수를 줄인다.**  \n",
    "이거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba8cdec",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "\n",
    "파라미터 많으면 2가지 문제가 있음  \n",
    "overfitting과 학습이 안되는 문제가 있는데 여기서는 overfitting은 아니고  \n",
    "층을 깊게 쌓아도 학습이 안되는 문제가 있었음  \n",
    "\n",
    "**skip connection**을 활용해서 해결  \n",
    "층의 출력값에 입력값을 더해서 두 값의 차이(residual)만큼 학습을 하도록 설정  \n",
    "\n",
    "더 깊게 쌓아서 학습을 시킬 수 있게 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5eaf00",
   "metadata": {},
   "source": [
    "### DenceNet\n",
    "\n",
    "skip connection으로 더하지 말고 concatenation을 하는 방법. 정보를 잃지 않기 위해  \n",
    "문제는 파라미터가 기하급수적으로 커짐  \n",
    "해결방법은 중간중간에 채널을 줄여줌  \n",
    "1x1 conv로  \n",
    "\n",
    "뭔가 만들어야겠다 그럼 ResNet이나 DenceNet쓰면 결과 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9f696a",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "- VGG : repeated 3x3 blocks\n",
    "- GoogLeNet : 1x1 convolution\n",
    "- RestNet : skip-connection\n",
    "- DenseNet : concatenation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98519c8d",
   "metadata": {},
   "source": [
    "# Computer Vision Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e05ffe5",
   "metadata": {},
   "source": [
    "### Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d1f1aa",
   "metadata": {},
   "source": [
    "이미지 한장에서 모든 픽셀에 라벨을 부여해서 여러가지 객체로 구분을 짓는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2df102",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda4d9ab",
   "metadata": {},
   "source": [
    "bounding box로 물체의 위치를 찾고 구분까지 하는 방법"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
