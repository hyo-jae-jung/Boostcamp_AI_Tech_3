Computer Vision
사진이나 비디오 등의 영상 정보로 장면의 본질을 파악하는 기술

그래픽스의 반대되는 개념이기 때문이 inverse graphics라고도 함.

1)-------------------------------------

1. Course overview

ai는 사람의 지능을 컴퓨터 시스템으로 구현하는건데 시각, 스피치, 결정, 번역을 포함한다.
Computer Vision에서는 시각인지(visual perception)를 다룬다.

지능은 포괄적이라 레퍼런스를 잡을 필요가 있는데 유아기의 인간의 성장을 기준으로 분석
인간은 5감으로 세상과 상호작용으로 학습하고 오감 뿐만아니라 표정, 스킨쉽, 말과 같은 social 감각도 학습한다.

75%의 정보를 눈으로 얻고, 뇌는 시각정보를 처리하는데 50%의 리소스를 사용하기 때문에
지능에서 지각능력의 획득이 중요함

그래서 Computer Vision(CV)이 뭐냐면
사진이나 비디오 등의 영상 정보로 장면의 본질을 파악하는 기술인데
Computer Graphics(CG)와 반대되는 개념이기 때문이 inverse graphics라고도 한다.

CV는 image를 hugh-level description로 Inverse rendering
CG는 hugh-level description을 image로 rendering

•Visual perception & intelligence 
o Input : visual data (image or video) 

•Class of visual perception 
o Color perception 
○ Motion perception 
○ 3D perception 
○ Semantic-level perception 
○ Social perception (emotion perception) 
○ Visuomotor perception, etc. 

•Also, computer vision includes understanding human visual perception capability

사람의 지각능력에는 편향이 있음. [Thatcher effect](https://en.wikipedia.org/wiki/Thatcher_effect)
컴퓨터는 이런 편향이 없이 이미지를 분석 할 수 있지만 결국 레이블은 사람이 만들기 때문에
해당 내용을 이해 및 인지하는 게 중요해보인다.

2. Image classification

fully conneted layer의 문제는 과적합이다.
이미지를 학습시켜도 cropped된 이미지로 테스트를 하면 이해하지 못한다. 이걸 해결한게 CNN이다.

cnn : fully connected layer -> fully locally connected layer

AlexNet
conv layer에서 linear layer로 가려면 flatten이나 average pooling이 필요.
이제 LRN(Local Response Normalization)은 잘 안 쓰고 Batch normalization이 잘 쓰임.
Receptive field : 종단 레이어를 만들기 위해 필요한 input space.

vgg
AlexNet의 형식은 유지하면서 개선이 이루어짐.
이미지 사이즈는 244x244로 AlexNet과 동일.
커널사이즈는 모두 3x3으로 변경. 커널사이즈를 줄여서 파라미터의 개수도 줄이고,
receptive field도 크게 가져가서 이미지의 많은 부분을 고려.
layer를 더 깊게 쌓음.
LRN 안 씀.

2)--------------------------------------------

1. Data augmentation
편향된 샘플 데이터를 실제 데이터에 다가가기 위해 사용하는 방법

밝기변환
crop
affine transformation
cutmix
RandAugmentation
등등 더 많음

2. Leveraging Pre-trained information

- Transfor learning = fine-tuning
    학습이 돼 있는 모델을 사용하려는 데이터셋에 맞춰서 사용하는 방법
    bottleneck : 사용하는 모델에 데이터를 통과시켜서 fc layer전에 나오는 features를 저장하고 이걸로 새로운 fc layer를 학습시키는 방법.
                 연산을 최소화 할 수 있는 장점이 있고 augmentation은 어려워 진다(왜? -> 이미지 하나로 bottleneck feature를 뽑아서 이미지를 무작위로 변형하여 여러개 bottleneck feature를 뽑으면 augmentation 효과 가능)
    bottleneck으로 학습시킨 fc layer를 학습이 된 모델에 붙이고 마지막 conv layer와 fc layer를 제외한 모든 layer를 freeze시켜서 학습시킨다.(하나의 예시임)
    추가적인 방법들은 해당 블로그에서 확인
    https://inhovation97.tistory.com/31

- Knowledge distillation

Entropy : 정보를 표현하는데 필요한 최소 자원량
Cross Entropy : 특정 전략을 쓸 때 예상되는 질문개수에 대한 기댓값
KL divergence : 정보량 차이

    Labeled data가 없어도 freeze된 teacher model과 student model에 동일한 input data를 입력해서 나온 loss의 차이인 KL div. Loss를 구해서 backpropagation으로 학습을 시킬 수 있다.
    Labeled data가 있으면 student model에 추가로 label(ground truth)과 비교해서 student loss를 구하고 distillation loss와 wight sum을 해서 backpropagation으로 학습을 시킬 수 있다.

3. Leveraging unlabeled dataset for training

- Semi-supervised learning
    label이 있는 작은 데이터셋으로 model을 학습시키고
    학습시킨 모델로 label이 없는 큰 데이터셋의 label을 만들어서
    작은 데이터셋와 큰 데이터셋을 합쳐서 기존 model or new model을 학습시킨다.

Self-training
    Augmentation + Teacher-Student networks + semi-supervised learning
    매우 성능이 좋은 모델

Brief overview of self-training

    1. Train initial teacher model with labeled data 
    2. Pseudo-label unlabeled data using teacher model 
    3. Train student model with both lableled and unlabeled data with augmentation 
    4. Set the student model as a new teacher, and set new model (bigger) as a new student 
    5. Repeat 2~4 with new teacher/student models


3)--------------------------------------

4)--------------------------------------
semantic segmentation

영상단위가 아니라 픽셀단위!

같은 영상에서 같은 클래스를 구분하지는 않고 하나로 인식
구분하는건 instance segmentation에서 다룸

의료, 무인자동차

fully convolutional networks(FCN)
alexnet은 입력 dimension과 출력 dimension이 다르면 안 좋은데
FCN은 달라도 됨.

1x1 conv 가 key point

upsampling??? -> reverse downsampling 

[U-Net]
skip connection -> residual block 만드는 작업

U-Net에서는 downsample과 upsample이 빈번히 일어나는데 
downsampling에서 영상 사이즈가 홀수면 나머지를 버리는데
upsampling 시 기존 영상 사이즈의 복원이 안되기 때문에
홀수 사이즈가 나오지 않도록 주의해야 한다.

[DeepLab]
CRFs
Attous Convolution
Dilated convolution

5)--------------------------------------------
Object detection

Semantic segmentation에서 진보된게
Instance segmentation, Panoptic segmentation인데
같은 class여도 instance의 구분이 가능해짐

bounding box는 좌표와 클래스 정보로 구성
classification + Box localization

Selective search

first object detection : R-CNN

Anchor boxes

챙겨야 될 키워드가 굉장히 많다 5강 집중하기

6-1)-----------------------------------------

Guided Grad-CAM

6-2)----------------------------------------

Autograd

hook:register_forward_hook
